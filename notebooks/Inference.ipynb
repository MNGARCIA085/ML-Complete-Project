{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb4de5f",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: darkblue;\">Inference</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8d630",
   "metadata": {},
   "source": [
    "### 📑 <font color='blue'> Table of Contents </font>\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup](#setup)\n",
    "3. [Load model and related components](#load)\n",
    "4. [Get new data](#new_data) \n",
    "5. [Preprocessing](#preprocessing)\n",
    "6. [Predictions](#predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6c02c",
   "metadata": {},
   "source": [
    "<a name=\"introduction\"></a>\n",
    "## <font color=\"darkred\"> 1. Introduction </font>\n",
    "\n",
    "In this notebook, we demonstrate how to use our trained model to make predictions on new data.\n",
    "\n",
    "The workflow is as follows:\n",
    "    \n",
    "- Load model and related components (scaler, encoder, etc.)\n",
    "\n",
    "- Get new data\n",
    "\n",
    "- Preprocess the data (scaling, encoding, feature selection, etc.)\n",
    "\n",
    "- Make predictions\n",
    "\n",
    "- Interpret the predictions\n",
    "\n",
    "This order ensures that the data is prepared exactly as during training before generating predictions, and then results can be meaningfully interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c2239",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## <font color=\"darkred\"> 2. Setup </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd829a30-b237-472a-9cb4-2259d76512f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 20:23:18.574986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d847d6",
   "metadata": {},
   "source": [
    "In this notebook we will focus on the last experiment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c1256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e26c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_best_model' from 'src.experiments.logging' (/home/marcos/Escritorio/AI-prod/ML-Complete-Project/src/experiments/logging.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(repo_root)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# now imports work\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_best_model\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_best_model' from 'src.experiments.logging' (/home/marcos/Escritorio/AI-prod/ML-Complete-Project/src/experiments/logging.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# go up one level (adjust if your notebook is deeper inside the repo)\n",
    "repo_root = os.path.abspath(\"..\")  \n",
    "sys.path.append(repo_root)\n",
    "\n",
    "# now imports work\n",
    "from src.experiments.logging import load_best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d139912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2815c2f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2252200555.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    which python\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "which python\n",
    "pip show mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7360acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d082e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_best_run_data(run_id):\n",
    "\n",
    "\n",
    "    # Also get run params & metrics if you want\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "    params = run.data.params\n",
    "    metrics = run.data.metrics\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"metrics\": metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f11cb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "def get_best_run_id(\n",
    "    experiment_name, \n",
    "    metric=\"recall\", \n",
    "    threshold=0.8, \n",
    "    sort_by=\"f1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the run_id of the best model with recall >= threshold, \n",
    "    ranked by another metric (default f1).\n",
    "    \"\"\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    exp = client.get_experiment_by_name(experiment_name)\n",
    "    if exp is None:\n",
    "        raise ValueError(f\"Experiment '{experiment_name}' not found.\")\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[exp.experiment_id],\n",
    "        filter_string=f\"metrics.{metric} >= {threshold}\",\n",
    "        order_by=[f\"metrics.{sort_by} DESC\"]\n",
    "    )\n",
    "    if not runs:\n",
    "        raise ValueError(f\"No runs found with {metric} >= {threshold}\")\n",
    "\n",
    "    return runs[0].info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57633086-7540-4473-8b82-17e5cd56c9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef0c7d-c96c-4245-b256-c94adf455ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a105b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Tuning\"\n",
    "\n",
    "# Find best run with recall >= 0.8, ranked by f1\n",
    "best_run_id = get_best_run_id(\n",
    "    experiment_name=experiment_name,\n",
    "    metric=\"recall\",\n",
    "    threshold=0.8,\n",
    "    sort_by=\"f1\"\n",
    ")\n",
    "\n",
    "# Now load everything\n",
    "data = load_best_run_data(best_run_id)\n",
    "\n",
    "\n",
    "\n",
    "params = data[\"params\"]\n",
    "metrics = data[\"metrics\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59a454b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model_name': 'model1',\n",
       "  'epochs': '2',\n",
       "  'learning_rate': '0.00544853401907757',\n",
       "  'dropout_rate': '0.4'},\n",
       " {'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'loss': 0.08368227630853653,\n",
       "  'accuracy': 1.0,\n",
       "  'f1_score': 0.999999995})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve, conf, matrix for thge best model........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b099d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "886d3d4d-7965-45f0-b5bc-9828c9e6dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments: ['experiment_baseline_standardize_20250905_192125']\n",
      "Latest experiment: experiment_baseline_standardize_20250905_192125\n",
      "Path to latest: ../outputs/saved_models/experiment_baseline_standardize_20250905_192125\n"
     ]
    }
   ],
   "source": [
    "# get last experiment\n",
    "\n",
    "base_path = \"../outputs/saved_models\"\n",
    "\n",
    "# list all experiment directories\n",
    "experiments = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "\n",
    "# sort them by timestamp at the end of the name\n",
    "experiments.sort()\n",
    "\n",
    "# last one (most recent)\n",
    "latest_experiment = experiments[-1]\n",
    "latest_path = os.path.join(base_path, latest_experiment)\n",
    "\n",
    "print(\"All experiments:\", experiments)\n",
    "print(\"Latest experiment:\", latest_experiment)\n",
    "print(\"Path to latest:\", latest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9b4e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = latest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8d9f3",
   "metadata": {},
   "source": [
    "<a name=\"load\"></a>\n",
    "## <font color=\"darkred\"> 3. Load model and related components </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe20ca6",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acdc948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(experiment_path, \"model.h5\")\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab835a-5e5d-4cb9-85e3-a17dc04b5ff7",
   "metadata": {},
   "source": [
    "**Load column names**\n",
    "\n",
    "Why do we need column names in AI projects?\n",
    "\n",
    "When training a model, the input features have a specific meaning and order. At inference time, if we feed the model data without the same structure, the predictions become unreliable. Column names act as a blueprint: they ensure new data is preprocessed consistently, features are aligned correctly, and nothing is misplaced or missing. Without them, the model might confuse inputs (e.g., treating \"age\" as \"income\"), leading to wrong results.\n",
    "\n",
    "In short: saving column names guarantees that training and inference speak the same “language.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "631ed99d-17c5-4a92-9921-6ce959e3aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load column names\n",
    "with open(f\"{experiment_path}/columns.json\", \"r\") as f:\n",
    "    columns = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6097b",
   "metadata": {},
   "source": [
    "**Load scaler and encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82fa8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = os.path.join(experiment_path, \"scaler.pkl\")\n",
    "encoder_path = os.path.join(experiment_path, \"encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b8e0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "mean: [1.41559238e+01 1.93511328e+01 9.21518750e+01 6.58153516e+02\n",
      " 9.61988672e-02 1.03554531e-01 8.85161713e-02 4.88897402e-02\n",
      " 1.81255273e-01 6.27087305e-02 4.09529102e-01 1.21794902e+00\n",
      " 2.90134512e+00 4.10547617e+01 6.94725781e-03 2.51113359e-02\n",
      " 3.16497336e-02 1.17416348e-02 2.04345078e-02 3.75897129e-03\n",
      " 1.63169453e+01 2.57480273e+01 1.07621934e+02 8.86556445e+02\n",
      " 1.32138906e-01 2.53280762e-01 2.71695561e-01 1.14682229e-01\n",
      " 2.90017188e-01 8.38891016e-02]\n",
      "var: [1.25668844e+01 1.85788022e+01 5.99698209e+02 1.26879396e+05\n",
      " 2.01562007e-04 2.81310339e-03 6.48463278e-03 1.53749022e-03\n",
      " 7.52674738e-04 4.73514193e-05 8.17568545e-02 3.12598201e-01\n",
      " 4.38201521e+00 2.22211910e+03 8.32386721e-06 2.98804298e-04\n",
      " 9.40867147e-04 3.93270921e-05 6.84521929e-05 6.59908845e-06\n",
      " 2.36568213e+01 3.76441772e+01 1.15197767e+03 3.32406115e+05\n",
      " 5.35499243e-04 2.45697564e-02 4.37180255e-02 4.36030274e-03\n",
      " 3.76101920e-03 3.24277262e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/.local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# scaler\n",
    "scaler = load(scaler_path)\n",
    "\n",
    "# See type of scaler\n",
    "print(type(scaler))\n",
    "\n",
    "# Main learned attributes\n",
    "print(\"mean:\", getattr(scaler, \"mean_\", None)) # mean for every feature\n",
    "print(\"var:\", getattr(scaler, \"var_\", None)) # variance for every feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c786c9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 1, 'B': 0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = joblib.load(encoder_path)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1684a46",
   "metadata": {},
   "source": [
    "<a name=\"new_data\"></a>\n",
    "## <font color=\"darkred\"> 4. Get new data </font>\n",
    "\n",
    "In this example, we will simulate some new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94193a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.39700385e+00, 4.00247407e+01, 6.34840096e+01, 2.06000060e+02,\n",
       "       2.72847655e-02, 2.26122734e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.81165733e-01, 7.59801867e-02, 1.26825215e-01, 2.36744378e+00,\n",
       "       3.73388939e+00, 1.14378116e+01, 3.98669556e-03, 2.59453102e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.42103882e-02, 1.96958698e-03,\n",
       "       1.09367534e+01, 1.50420000e+01, 4.19445884e+01, 2.18346708e+02,\n",
       "       8.44272781e-02, 9.01674345e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.24245112e-01, 2.56945024e-02])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original data for reference\n",
    "original = np.array([7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, 0.0, 0.0,\n",
    "       0.1587, 0.05884, 0.3857, 1.428, 2.548, 19.15, 0.007189, 0.00466,\n",
    "       0.0, 0.0, 0.02676, 0.002783, 9.456, 30.37, 59.16, 268.6, 0.08996,\n",
    "       0.06444, 0.0, 0.0, 0.2871, 0.07039])\n",
    "\n",
    "# Generate a new vector: similar scale, but perturbed enough\n",
    "np.random.seed(42)  # for reproducibility\n",
    "noise_factor = 0.7  # larger factor → more difference\n",
    "new_data = original * (1 + noise_factor * (2 * np.random.rand(*original.shape) - 1))\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39103f49",
   "metadata": {},
   "source": [
    "<a name=\"preprocessing\"></a>\n",
    "## <font color=\"darkred\"> 5. Preprocess new data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f22a1aed-5696-45d3-b0d7-67a47fd2c656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.397004</td>\n",
       "      <td>40.024741</td>\n",
       "      <td>63.48401</td>\n",
       "      <td>206.00006</td>\n",
       "      <td>0.027285</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181166</td>\n",
       "      <td>0.07598</td>\n",
       "      <td>...</td>\n",
       "      <td>10.936753</td>\n",
       "      <td>15.042</td>\n",
       "      <td>41.944588</td>\n",
       "      <td>218.346708</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324245</td>\n",
       "      <td>0.025695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     6.397004     40.024741        63.48401  206.00006         0.027285   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          0.022612             0.0                  0.0       0.181166   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07598  ...     10.936753         15.042        41.944588   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  218.346708          0.084427           0.090167              0.0   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                   0.0        0.324245                 0.025695  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column names\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "new_data_df = pd.DataFrame([new_data], columns=columns)\n",
    "\n",
    "# visualization\n",
    "new_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "537c3f6c-4506-4ab2-86f5-5ea7046bdb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.18870618e+00,  4.79631192e+00, -1.17065515e+00,\n",
       "        -1.26937606e+00, -4.85404461e+00, -1.52609816e+00,\n",
       "        -1.09920812e+00, -1.24684236e+00, -3.26372864e-03,\n",
       "         1.92864403e+00, -9.88711742e-01,  2.05595572e+00,\n",
       "         3.97713558e-01, -6.28284966e-01, -1.02615183e+00,\n",
       "        -1.30260681e+00, -1.03182467e+00, -1.87233109e+00,\n",
       "         4.56377834e-01, -6.96565004e-01, -1.10616414e+00,\n",
       "        -1.74493577e+00, -1.93505609e+00, -1.15898629e+00,\n",
       "        -2.06179179e+00, -1.04061246e+00, -1.29942816e+00,\n",
       "        -1.73675198e+00,  5.58120260e-01, -3.23165085e+00]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data = scaler.transform(new_data_df)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef49a6c-4f42-475d-a288-c3b70ef7cc6c",
   "metadata": {},
   "source": [
    "<a name=\"predictions\"></a>\n",
    "## <font color=\"darkred\"> 6. Predictions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc1f0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.0527065e-05]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(scaled_data)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031559d-a406-46fd-b55b-563bd1bd173b",
   "metadata": {},
   "source": [
    "That probability is about 0.0000705 (≈0.007%), which is extremely close to zero—indicating the model is almost certain the tumor is not malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3272b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
