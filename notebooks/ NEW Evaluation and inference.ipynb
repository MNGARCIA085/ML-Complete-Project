{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002f331-f34f-4b06-8277-935b42cb721c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0b594e6-8b57-4ba2-a9cf-ad17cbd2582c",
   "metadata": {},
   "source": [
    "-> Load model, preprocessing artifacts\n",
    "\n",
    "also metrics and show them\n",
    "\n",
    "-> Load plots and show them (roc, confussion matrix)\n",
    "\n",
    "-> Make inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d759d8c-546b-4227-9521-3756212fe51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42182807-72a0-4b78-85c7-23377c218c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4f312-8241-4bba-82c6-146089ab5f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3406a945-f95f-428e-bdcf-6f81929ae10d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba00a4f2-bb6f-4134-b9a2-aea08616edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete MLflow loader for best run\n",
    "import mlflow\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import mlflow.tensorflow\n",
    "from mlflow.entities import ViewType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122024f-0f45-42f4-a75b-39af39cf39e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f4c50-0443-4f7a-9830-f47e4fce2f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e87e45d9-1c00-4a9c-9361-4f209bbab150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_best_model(results, recall_threshold=0.8, metric_priority=\"f1_score\"):\n",
    "    # Step 1: filter candidates by recall\n",
    "    candidates = [res for res in results if res[\"metrics\"].get(\"recall\", 0) >= recall_threshold]\n",
    "\n",
    "    # Step 2: among candidates, pick the one with best priority metric\n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda r: r[\"metrics\"].get(metric_priority, float(\"-inf\")))\n",
    "    \n",
    "    # Step 3: fallback – best recall overall\n",
    "    return max(results, key=lambda r: r[\"metrics\"].get(\"recall\", float(\"-inf\")))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_best_run(runs, recall_threshold=0.8, metric_priority=\"f1_score\"):\n",
    "    \"\"\"\n",
    "    Select the best run based on recall threshold and a priority metric.\n",
    "    \n",
    "    Args:\n",
    "        runs (list of dict): Each dict should contain:\n",
    "            - \"metrics\" (dict)\n",
    "            - \"params\" (dict)\n",
    "            - \"tags\" (dict)\n",
    "            - \"run_id\" (str)\n",
    "            - \"artifact_uri\" (str)\n",
    "        recall_threshold (float): Minimum recall to be considered a candidate.\n",
    "        metric_priority (str): Metric to use when multiple candidates meet threshold.\n",
    "\n",
    "    Returns:\n",
    "        dict: The best run dictionary.\n",
    "    \"\"\"\n",
    "    # Filter candidates by recall\n",
    "    candidates = [r for r in runs if r[\"metrics\"].get(\"recall\", 0) >= recall_threshold]\n",
    "\n",
    "    # Pick best among candidates\n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda r: r[\"metrics\"].get(metric_priority, float(\"-inf\")))\n",
    "\n",
    "    # Fallback: best recall overall\n",
    "    return max(runs, key=lambda r: r[\"metrics\"].get(\"recall\", float(\"-inf\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49bc0e-1112-43cc-b700-2c306597f6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb3384-665e-4b6d-a4ea-1e3db2e07ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662a5b3-bc9c-46a2-987e-2c9301da9c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9200996-a119-4fa1-8241-b8e1bebe8dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: 0106566d6efd453a8b905ba3690ecd2a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# CONFIG\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "experiment_name = \"Tuning\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Experiment '{experiment_name}' not found.\")\n",
    "    \n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "\n",
    "\n",
    "tracking_uri = \"http://127.0.0.1:5000\"        # your MLflow server\n",
    "experiment_id = experiment_id         # experiment ID from UI\n",
    "metric_to_sort = \"f1\"                        # metric to choose the best run\n",
    "artifact_paths = {\n",
    "    \"preprocessing\": \"preprocessing\",       # folder under artifacts\n",
    "    \"model\": \"model\"                         # model artifact path\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# SET TRACKING URI\n",
    "# --------------------------\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "# --------------------------\n",
    "# SEARCH BEST RUN\n",
    "# --------------------------\n",
    "\n",
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"tags.mlflow.runName = 'best_overall'\", # ONLY SEARCHG in best runs\n",
    ")\n",
    "\n",
    "\n",
    "# Convert MLflow DataFrame to list of dicts\n",
    "runs = []\n",
    "for _, row in runs_df.iterrows():\n",
    "    runs.append({\n",
    "        \"run_id\": row[\"run_id\"],\n",
    "        \"metrics\": {k.replace(\"metrics.\", \"\"): row[k] for k in row.index if k.startswith(\"metrics.\")},\n",
    "        \"params\": {k.replace(\"params.\", \"\"): row[k] for k in row.index if k.startswith(\"params.\")},\n",
    "        \"tags\": {k.replace(\"tags.\", \"\"): row[k] for k in row.index if k.startswith(\"tags.\")},\n",
    "        \"artifact_uri\": row[\"artifact_uri\"]\n",
    "    })\n",
    "\n",
    "best_run = get_best_run(runs, recall_threshold=0.8, metric_priority=\"f1_score\")\n",
    "print(\"Best run ID:\", best_run[\"run_id\"])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "best_runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    order_by=[f\"metrics.{metric_to_sort} DESC\"],\n",
    "    filter_string=\"tags.mlflow.runName = 'best_overall'\", # ONLY SEARCHG in best runs\n",
    "    max_results=1\n",
    ")\n",
    "if best_runs.empty:\n",
    "    raise ValueError(\"No runs found in the experiment!\")\n",
    "\n",
    "best_run = best_runs.iloc[0]\n",
    "run_id = best_run.run_id\n",
    "print(f\"Best run_id: {run_id}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "run_id = best_run[\"run_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06780075-df4a-43ec-a7eb-c9184da9c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': '0106566d6efd453a8b905ba3690ecd2a',\n",
       " 'metrics': {'loss': 0.08819971233606339,\n",
       "  'accuracy': 1.0,\n",
       "  'f1_score': 0.999999995,\n",
       "  'test_precision': 0.9756097793579102,\n",
       "  'precision': 1.0,\n",
       "  'test_f1': 0.9638554294926511,\n",
       "  'test_recall': 0.9523809552192688,\n",
       "  'test_accuracy': 0.9736841917037964,\n",
       "  'recall': 1.0,\n",
       "  'test_loss': 0.11360521614551544},\n",
       " 'params': {'dropout_rate': '0.4',\n",
       "  'model_name': 'model1',\n",
       "  'epochs': '2',\n",
       "  'learning_rate': '0.00544853401907757'},\n",
       " 'tags': {'mlflow.source.git.commit': '5c4bd9d8d45fdc2f13e460ddf330262a85a581d2',\n",
       "  'mlflow.user': 'marcos',\n",
       "  'mlflow.runName': 'best_overall',\n",
       "  'mlflow.source.name': '/home/marcos/Escritorio/AI-prod/ML-Complete-Project/scripts/pipeline.py',\n",
       "  'mlflow.source.type': 'LOCAL'},\n",
       " 'artifact_uri': 'file:///home/marcos/Escritorio/AI-prod/ML-Complete-Project/mlruns/694254336158470969/0106566d6efd453a8b905ba3690ecd2a/artifacts'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a644d5a-a4cc-4d89-950b-746f09357bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'dropout_rate': '0.4', 'model_name': 'model1', 'epochs': '2', 'learning_rate': '0.00544853401907757'}\n",
      "Metrics: {'loss': 0.08819971233606339, 'accuracy': 1.0, 'f1_score': 0.999999995, 'test_precision': 0.9756097793579102, 'precision': 1.0, 'test_f1': 0.9638554294926511, 'test_recall': 0.9523809552192688, 'test_accuracy': 0.9736841917037964, 'recall': 1.0, 'test_loss': 0.11360521614551544}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# LOAD PARAMS AND METRICS\n",
    "# --------------------------\n",
    "params = best_run['params']\n",
    "metrics = best_run['metrics']\n",
    "print(\"Params:\", params)\n",
    "print(\"Metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0825f-5911-46f0-968e-0b9fe49f2e77",
   "metadata": {},
   "source": [
    "### Preprocessing artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9465a913-b1d5-4178-a5e0-8c4e2ceb9819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing artifacts downloaded to: /tmp/tmpbgyajal5/preprocessing\n",
      "Scaler, encoder, and features loaded successfully!\n",
      "TensorFlow model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# DOWNLOAD PREPROCESSING ARTIFACTS\n",
    "# --------------------------\n",
    "preproc_dir = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=artifact_paths[\"preprocessing\"])\n",
    "print(\"Preprocessing artifacts downloaded to:\", preproc_dir)\n",
    "\n",
    "# Load scaler\n",
    "scaler_file = os.path.join(preproc_dir, \"scaler.pkl\")\n",
    "with open(scaler_file, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Load encoder\n",
    "encoder_file = os.path.join(preproc_dir, \"encoder.pkl\")\n",
    "with open(encoder_file, \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# Load features\n",
    "features_file = os.path.join(preproc_dir, \"features.json\")\n",
    "with open(features_file, \"r\") as f:\n",
    "    features = json.load(f)\n",
    "\n",
    "print(\"Scaler, encoder, and features loaded successfully!\")\n",
    "\n",
    "# --------------------------\n",
    "# LOAD MODEL\n",
    "# --------------------------\n",
    "model_uri = f\"runs:/{run_id}/{artifact_paths['model']}\"\n",
    "model = mlflow.tensorflow.load_model(model_uri)\n",
    "print(\"TensorFlow model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ccd12b8-64e8-4648-b2c4-d93ff64c96d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': ['radius_mean',\n",
       "  'texture_mean',\n",
       "  'perimeter_mean',\n",
       "  'area_mean',\n",
       "  'smoothness_mean',\n",
       "  'compactness_mean',\n",
       "  'concavity_mean',\n",
       "  'concave points_mean',\n",
       "  'symmetry_mean',\n",
       "  'fractal_dimension_mean',\n",
       "  'radius_se',\n",
       "  'texture_se',\n",
       "  'perimeter_se',\n",
       "  'area_se',\n",
       "  'smoothness_se',\n",
       "  'compactness_se',\n",
       "  'concavity_se',\n",
       "  'concave points_se',\n",
       "  'symmetry_se',\n",
       "  'fractal_dimension_se',\n",
       "  'radius_worst',\n",
       "  'texture_worst',\n",
       "  'perimeter_worst',\n",
       "  'area_worst',\n",
       "  'smoothness_worst',\n",
       "  'compactness_worst',\n",
       "  'concavity_worst',\n",
       "  'concave points_worst',\n",
       "  'symmetry_worst',\n",
       "  'fractal_dimension_worst']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322bd2bf-ceb4-483f-8ea0-c2fb608329d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 1, 'B': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11acb7e2-75aa-4570-bf19-390f33972748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41559238e+01, 1.93511328e+01, 9.21518750e+01, 6.58153516e+02,\n",
       "       9.61988672e-02, 1.03554531e-01, 8.85161713e-02, 4.88897402e-02,\n",
       "       1.81255273e-01, 6.27087305e-02, 4.09529102e-01, 1.21794902e+00,\n",
       "       2.90134512e+00, 4.10547617e+01, 6.94725781e-03, 2.51113359e-02,\n",
       "       3.16497336e-02, 1.17416348e-02, 2.04345078e-02, 3.75897129e-03,\n",
       "       1.63169453e+01, 2.57480273e+01, 1.07621934e+02, 8.86556445e+02,\n",
       "       1.32138906e-01, 2.53280762e-01, 2.71695561e-01, 1.14682229e-01,\n",
       "       2.90017188e-01, 8.38891016e-02])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86d4a7-d742-4976-b66f-6aa6cc762cf0",
   "metadata": {},
   "source": [
    "# si aprovecho y guardo plots los cargo acá (roc,......)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cbe70-a47e-4496-b099-63e0e188677c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f2115f-fa0f-40ba-80de-776016eb930b",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6893ae8-d881-4510-9ceb-6816f5ade3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "new_data = np.random.rand(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f76bd82-a1c0-46a8-a80d-58b89d307106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.81011976e+00, -4.47525609e+00, -3.74545648e+00,\n",
       "        -1.84687726e+00,  4.19432661e+01,  8.41945848e+00,\n",
       "         2.83769982e+00, -1.22895558e+00,  7.98952583e+00,\n",
       "         7.86905115e+01,  1.29262186e+00, -1.98880820e+00,\n",
       "        -1.35052227e+00, -8.56502669e-01,  2.65027253e+02,\n",
       "         5.14739301e+01,  2.56959617e+01,  2.48886110e+01,\n",
       "         6.08471218e+01,  1.07568650e+02, -3.32748876e+00,\n",
       "        -4.05974255e+00, -3.15387939e+00, -1.53667235e+00,\n",
       "         1.88609715e+01,  4.28283368e+00,  3.30790906e+00,\n",
       "         8.97685839e+00, -1.22624044e-01,  1.22801038e+01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame with proper column names\n",
    "new_data_df = pd.DataFrame([new_data], columns=features['features'])\n",
    "\n",
    "scaled_data = scaler.transform(new_data_df)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffa0520f-8e23-4b5d-ace4-12bd00ab1bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47d45bd9-e5a6-4a10-b245-43d7823f8d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4497193e-22]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86ce2bb9-86f9-4308-9eaa-548825d78b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.49124866e-01, 6.13761888e-02, 4.30378660e-01, 2.93356330e-01,\n",
       "       6.91678048e-01, 5.50111639e-01, 3.17028242e-01, 7.01355829e-04,\n",
       "       4.00447261e-01, 6.04196771e-01, 7.79130481e-01, 1.05996769e-01,\n",
       "       7.42612669e-02, 6.79775500e-01, 7.71580382e-01, 9.14887461e-01,\n",
       "       8.19836300e-01, 1.67821391e-01, 5.23858283e-01, 2.80088752e-01,\n",
       "       1.32612830e-01, 8.39537527e-01, 5.76754949e-01, 5.93051626e-01,\n",
       "       5.68597943e-01, 9.24603929e-01, 9.63341499e-01, 7.07447424e-01,\n",
       "       2.82497004e-01, 3.05025527e-01])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "592fba2e-161f-475b-a8e0-160285fde29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,293</span> (48.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,293\u001b[0m (48.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,196</span> (32.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m8,196\u001b[0m (32.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbf2cc-ac77-400f-b540-86f0e3e87f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
